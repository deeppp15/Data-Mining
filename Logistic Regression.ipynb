{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "656de3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "delimiter = \"\\t\"\n",
    "\n",
    "# load the data into a pandas dataframe\n",
    "df = pd.read_csv(\"TrainData.dat\", delimiter=delimiter, header=None,names=['label','sentence'])\n",
    "\n",
    "#Fill any null values if present\n",
    "df['label'].fillna(0,inplace=True)\n",
    "df['sentence'].fillna('NA',inplace=True)\n",
    "\n",
    "#Seperate columns from training data into labels and sentences\n",
    "labels = df['label'].tolist()\n",
    "sentences = df['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "f5d34e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessor(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.digits))\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Join the tokens back into a sentence\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b70d6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply count vectorizer to form a bag of words  and also convert them into lowercase\n",
    "cv1 = CountVectorizer(preprocessor=preprocessor,max_df=0.75,min_df=1)\n",
    "X = cv1.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "8e8ca373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8733117233927606\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,labels, test_size=0.2, random_state=4)\n",
    "\n",
    "# initialize the logistic regression model setting max_iter because the data is large\n",
    "model = LogisticRegression(solver='lbfgs',max_iter=1000)\n",
    "\n",
    "# fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model's accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "2b11c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After our model is trained on the training data, we apply it on our test data\n",
    "# Reading sentences from test data file\n",
    "fo = open(\"TestData.dat\", \"r\")\n",
    "fread = fo.readlines()\n",
    "sentences=[]\n",
    "count=0\n",
    "for line in fread:\n",
    "    count+=1\n",
    "    sentences.append(line.split(\"\\n\"))\n",
    "\n",
    "fo.close() # Closing file\n",
    "df_Test = pd.DataFrame({'sentence':sentences}) #Converting into dataFrame for predictions\n",
    "#print(df_Test)\n",
    "\n",
    "NewSentences= df['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "bf3d4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = cv1.fit_transform(NewSentences) \n",
    "#Applying the same model with 0.87 accuracy on our Test data\n",
    "y_pred = model.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "8ddcd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file in write mode\n",
    "file = open(\"Deep_Vora_Output.txt\", \"w\") \n",
    "\n",
    "for i, item in enumerate(y_pred):\n",
    "    #if item == -1: #for debugging the results\n",
    "       # print(\"Index:\", i,sentences[i],\":- \", \"Value:\", item) #for debugging the results\n",
    "    file.write(str(item) + \"\\n\") # Writing data to the output file\n",
    "\n",
    "# Close the file to save changes\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645bcef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
